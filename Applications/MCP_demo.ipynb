{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A demonstration on leveraging MCP capabilities with SLMs for performing simple tasks. My efforts are towards performing everything from scratch for better visibility of the complete process. The task at hand is to select best restaurant in Sydney on the basis of reviews and ratings.\n",
    "P.S This notebook is not complete and is under active development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable this install the required dependencies\n",
    "# !pip install ollama selenium beautifulsoup4 webdriver-manager requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import time\n",
    "import platform\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import necessary Service objects and managers (handle Safari separately)\n",
    "try:\n",
    "    from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "    from webdriver_manager.chrome import ChromeDriverManager\n",
    "except ImportError:\n",
    "    ChromeService = None\n",
    "    ChromeDriverManager = None\n",
    "\n",
    "try:\n",
    "    from selenium.webdriver.firefox.service import Service as FirefoxService\n",
    "    from webdriver_manager.firefox import GeckoDriverManager\n",
    "except ImportError:\n",
    "    FirefoxService = None\n",
    "    GeckoDriverManager = None\n",
    "\n",
    "try:\n",
    "    from selenium.webdriver.safari.service import Service as SafariService\n",
    "except ImportError:\n",
    "    SafariService = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "OLLAMA_MODEL = #Enter your model name\n",
    "SEARCH_ENGINE_URL = \"https://html.duckduckgo.com/html/\"  # HTML version of DuckDuckGo\n",
    "SEARCH_QUERY = \"best restaurants Sydney reviews ratings\"\n",
    "BROWSER_CHOICE = 'safari'  # Change to your desired browser ('chrome', 'firefox', or 'safari')\n",
    "MAX_LINKS_TO_SEARCH = 3  # Number of website links to deep-search\n",
    "WAIT_TIMEOUT = 10  # Seconds to wait for elements\n",
    "RUN_HEADLESS = True  # Set to False to see the browser window\n",
    "\n",
    "# --- CSS Selectors for HTML DuckDuckGo ---\n",
    "DDG_RESULT_BLOCK_SELECTOR = \"div.result\"\n",
    "DDG_LINK_SELECTOR = \"a.result__a\"  # Links inside the result blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utility functions ---\n",
    "\n",
    "def setup_driver(browser_choice, headless=True):\n",
    "    \"\"\"Sets up the Selenium WebDriver.\"\"\"\n",
    "    print(f\"Setting up Selenium WebDriver for {browser_choice}...\")\n",
    "    effective_headless = headless\n",
    "    try:\n",
    "        if browser_choice.lower() == 'chrome':\n",
    "            if not ChromeService or not ChromeDriverManager:\n",
    "                raise ImportError(\"Chrome components not installed. Run 'pip install selenium webdriver-manager'\")\n",
    "            options = webdriver.ChromeOptions()\n",
    "            if headless:\n",
    "                options.add_argument('--headless')\n",
    "            options.add_argument('--no-sandbox')\n",
    "            options.add_argument('--disable-dev-shm-usage')\n",
    "            service = ChromeService(ChromeDriverManager().install())\n",
    "            driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "        elif browser_choice.lower() == 'firefox':\n",
    "            if not FirefoxService or not GeckoDriverManager:\n",
    "                raise ImportError(\"Firefox components not installed. Run 'pip install selenium webdriver-manager'\")\n",
    "            options = webdriver.FirefoxOptions()\n",
    "            if headless:\n",
    "                options.add_argument('--headless')\n",
    "            service = FirefoxService(GeckoDriverManager().install())\n",
    "            driver = webdriver.Firefox(service=service, options=options)\n",
    "\n",
    "        elif browser_choice.lower() == 'safari':\n",
    "            if platform.system() != 'Darwin':\n",
    "                raise SystemError(\"Safari automation is only supported on macOS.\")\n",
    "            if not SafariService:\n",
    "                raise ImportError(\"Safari components could not be imported.\")\n",
    "            if headless:\n",
    "                print(\"Warning: Safari does not reliably support headless mode via Selenium. Running with visible window.\")\n",
    "                effective_headless = False\n",
    "            print(\"INFO: Ensure 'Allow Remote Automation' is enabled in Safari's Develop menu.\")\n",
    "            options = webdriver.SafariOptions()\n",
    "            driver = webdriver.Safari(options=options)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported browser choice. Use 'chrome', 'firefox', or 'safari'.\")\n",
    "\n",
    "        print(f\"WebDriver setup complete (Headless: {effective_headless}).\")\n",
    "        return driver, effective_headless\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up WebDriver: {e}\")\n",
    "        raise\n",
    "\n",
    "def perform_duckduckgo_search(driver, query):\n",
    "    \"\"\"Performs a search on the HTML version of DuckDuckGo.\"\"\"\n",
    "    print(f\"Performing search for: '{query}' on {SEARCH_ENGINE_URL}\")\n",
    "    try:\n",
    "        driver.get(SEARCH_ENGINE_URL)\n",
    "        time.sleep(1)  # Let the page load\n",
    "\n",
    "        # In the HTML version, the search box has name \"q\"\n",
    "        search_box = WebDriverWait(driver, WAIT_TIMEOUT).until(\n",
    "            EC.presence_of_element_located((By.NAME, 'q'))\n",
    "        )\n",
    "        search_box.send_keys(query)\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "        print(\"Search submitted. Waiting for results...\")\n",
    "        WebDriverWait(driver, WAIT_TIMEOUT).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, DDG_RESULT_BLOCK_SELECTOR))\n",
    "        )\n",
    "        print(\"Search results loaded.\")\n",
    "        return driver.page_source\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"Error: Timed out waiting for DuckDuckGo elements.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during search: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_search_result_links(html_content):\n",
    "    \"\"\"Scrapes the first few result links from the HTML version of DuckDuckGo.\"\"\"\n",
    "    links = []\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    result_blocks = soup.select(DDG_RESULT_BLOCK_SELECTOR)\n",
    "    print(f\"Found {len(result_blocks)} result blocks.\")\n",
    "    for block in result_blocks:\n",
    "        link_tag = block.select_one(DDG_LINK_SELECTOR)\n",
    "        if link_tag and link_tag.has_attr('href'):\n",
    "            links.append(link_tag['href'])\n",
    "            print(f\"Scraped link: {link_tag['href']}\")\n",
    "        if len(links) >= MAX_LINKS_TO_SEARCH:\n",
    "            break\n",
    "    return links\n",
    "\n",
    "def deep_search_on_site(driver, url):\n",
    "    \"\"\"Visits the given URL and extracts main textual content.\"\"\"\n",
    "    print(f\"\\nDeep searching site: {url}\")\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # Allow time for page load; adjust as needed\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        # A simple heuristic: get the text of the <body>\n",
    "        body = soup.find('body')\n",
    "        if body:\n",
    "            text = body.get_text(separator=' ', strip=True)\n",
    "            print(f\"Extracted {len(text)} characters from {url}\")\n",
    "            return text\n",
    "        else:\n",
    "            print(\"No <body> found.\")\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error during deep search of {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def analyze_deep_results_with_ollama(deep_results, query):\n",
    "    \"\"\"Aggregates deep search content and sends it to Ollama for analysis.\"\"\"\n",
    "    print(f\"\\nSending deep search results from {len(deep_results)} websites to Ollama...\")\n",
    "    if not deep_results:\n",
    "        return \"No deep search results to analyze.\"\n",
    "    \n",
    "    context = f\"Deep search results for query '{query}':\\n\\n\"\n",
    "    for idx, result in enumerate(deep_results):\n",
    "        context += f\"Website {idx+1} ({result['url']}):\\n\"\n",
    "        # Optionally limit the amount of text passed (e.g., first 1000 characters)\n",
    "        snippet = result['content'][:1000]\n",
    "        context += snippet + \"\\n\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "{context}\n",
    "Based on the content extracted from the above websites, which one appears to offer the best detailed information on good restaurants in Sydney? \n",
    "Please explain your reasoning and identify the website (by its URL) that seems most promising.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=OLLAMA_MODEL,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': 'You are an AI assistant analyzing deep search results for restaurant information.'},\n",
    "                {'role': 'user', 'content': prompt}\n",
    "            ]\n",
    "        )\n",
    "        print(\"Ollama analysis complete.\")\n",
    "        return response['message']['content']\n",
    "    except Exception as e:\n",
    "        print(f\"Error communicating with Ollama: {e}\")\n",
    "        return f\"Error analyzing results: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    driver = None\n",
    "    try:\n",
    "        # 1. Setup WebDriver\n",
    "        driver, _ = setup_driver(BROWSER_CHOICE, RUN_HEADLESS)\n",
    "        \n",
    "        # 2. Perform DuckDuckGo Search (HTML version)\n",
    "        html = perform_duckduckgo_search(driver, SEARCH_QUERY)\n",
    "        if not html:\n",
    "            print(\"Failed to retrieve search page content.\")\n",
    "            exit(1)\n",
    "        \n",
    "        # 3. Scrape the first few result links\n",
    "        links = scrape_search_result_links(html)\n",
    "        if not links:\n",
    "            print(\"No result links found.\")\n",
    "            exit(1)\n",
    "        \n",
    "        # 4. Deep search each website and collect content\n",
    "        deep_results = []\n",
    "        for url in links:\n",
    "            content = deep_search_on_site(driver, url)\n",
    "            if content:\n",
    "                deep_results.append({'url': url, 'content': content})\n",
    "            else:\n",
    "                print(f\"Skipping {url} due to lack of content.\")\n",
    "        \n",
    "        if not deep_results:\n",
    "            print(\"No deep search results obtained from the websites.\")\n",
    "        else:\n",
    "            # 5. Analyze the aggregated deep search content with Ollama\n",
    "            analysis_result = analyze_deep_results_with_ollama(deep_results, SEARCH_QUERY)\n",
    "            print(\"\\n\" + \"=\"*20 + \" FINAL DEEP SEARCH ANALYSIS \" + \"=\"*20)\n",
    "            print(analysis_result)\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "    finally:\n",
    "        if driver:\n",
    "            print(\"\\nClosing the browser...\")\n",
    "            driver.quit()\n",
    "            print(\"Browser closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
